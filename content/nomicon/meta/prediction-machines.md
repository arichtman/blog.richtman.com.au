+++
title = "Prediction Machines"
date = 1970-01-01
description = "Summary of the 2022 revised edition."
[taxonomies]
categories = [ "Personal", "Meta" ]
tags = [ "reference", "book", "professional-development", "summary" ]
+++

# Prediction Machines

## Introduction

AI is a prediction technology, predictions are inputs to decision-making, and economics provides a perfect framework for understanding the trade-offs underlying any decision.

When the price of something falls, we use more of it. [Ed. Jevon's Paradox]

Reframing a technological advance as a shift from expensive to cheap or from scarce to abundant is invaluable for thinking...

When an input such as prediction becomes cheap, this can enhance the value of other things. Economists call these "complements".

[In order to strategise]
First, you must invest in gathering intelligence on how fast and how far the dial on the prediction machines will turn for your sector and applications.
Second, you must invest in developing a thesis about the strategic options created from turning the dial.

Prediction facilitatec decisions by reducing uncertainty, while judgement assigns value.

Judgement is the skill used to determine a payoff, utility, reward, or profit.

The most significant implication of prediction machines is that they increase the value of judgement.

## Prediction

Prediction is the process of filling in missing information.
Prediction takes information you have, often called data, and uses it to generate information you don't have.

The change frm 98% to 99.9% has been transformational.
An improvement frm 98% to 99.9% means mistakes fall by a factor of twenty.

A decision maker is _risk averse_ if they chose not to take a fair bet.

If risk exposure is not the constraint, then insurance won't do anything.

When forecasts are imperfect, it becomes important what is going on under the hood.

_Option Value_ is the value of not committing until as late as possible.

Risk can be managed in two broad ways.
- _Insurance_: take actions that reduce the costs associated with bad outcomes.
- _Protection_: take actions that reduce the probability of a bad outcome.

When you use insurance tto minimize wast, the waste is visible.
By contrast, with protection, the waste may be harder to see.

[_Regression_] Finds a prediction based on the average of what has occurred in the past.

_The Conditional Average_

_Goodness of Fit_

_Customer Churn_

Regression minimizes prediction mistakes on average, and punishes large errors more than small ones.

Even if it averabes out to the correct answer, regression can mean never actually hitting the target.
Unlike regression, machine learning predictions might be wrong on average, but when the predictions miss, they often don't miss by much.

_Deep Learning_

_Back Propagation_

Traditional statistical methods require the articulation of hypotheses or at least of human intuition for a model specification.
Machine learning has less need to specify in advance what goes into the model and can accommodate the equivalent of much more complex models with many more interactiosn between variables.

_The New Oil_ == Data

Three types of data for AI:
- _Input data_: fed to the algorithm and used to produce a prediction.
- _Training data_: used to generate the algorithm in the first place.
- _Feedback data_: used to improve the algorIthm's performance with experience.
In some situations, considerable overlap exists, such that the same data plays all 3 roles.

_Independent Variables_

_Dependent Variables_

The number of individuals [units of analysis, data] required depends on two factors:
first, how reliable the signal is relative to the noise
second, how accurate the prediction must be to be useful

_Power Calculations_: tools for assessing the amount of data required given the expected reliability of the prediction and the need for accuracy.

Accurate prdictions require more units to study, and acquiring these additional units can be costly.

Data may have increasing or decreasing returns to scale.
Decreasing returns to scale means as you get more data, each additional piece is less valuable.
This might not be true when considering the outcomes and costs.

Understand the relationship between adding more data, enmancing prediction accuracy, and increasing value creation.

The larger the number of events, the likelier the outcome will be close to the average.

The interaction effect means as the number of dimensions for interactions grows, humans' ability to form accurate prections diminishes.

_Known Knowns_: rich data, good predictions
_Known Unknowns_: too little data, difficult to predict
_Unknown Unknowns_: events not captured by past experience or what is present in the data but nonetheless possible. Black Swan.
_Unknown Knowns_: wrong but confident predictions?

_Reverse Causality_

_Omitted Variables_: factors that influence but aren't in the input data or model

_Counterfactual_: what would have happened if you had taken a different action

Once unmodeled situations have been identified, they are no longer unknown knowns.
Either they find solutions to generate good predictions, so the problems become known knowns.
Or they cannot find solutions, so they become known unknowns

The blending of AI for prediction and humans for judgement is classic division of labour.
Either the prediction is provided to the human to combine with their own assessment.
Or the prediction can be used for assessment or a second opinion after the fact.

Prediction machines can scale in a way humans can't.
But they struggle to predict in unusual cases for which there's not much data.

_Prediction by Exception_: the prediction machine runs as normal, but when it hits an exceptional case, a human is called to intervene.

## Decision-Making

p85
